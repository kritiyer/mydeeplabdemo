{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mydeeplab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kritiyer/mydeeplabdemo/blob/master/AngioNet_save_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO5vIf8HgUyq",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0731aa7-b4b6-45cc-82b8-9af10fa849cb"
      },
      "source": [
        "#@title Upload model.py\n",
        "# from google.colab import files\n",
        "# files.upload()\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd \"/content/gdrive/My Drive/CritikAlNet demo/\"\n",
        "\n",
        "%ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CritikAlNet demo\n",
            "\u001b[0m\u001b[01;34m5goodimages\u001b[0m/                      \u001b[01;34mgoodimages\u001b[0m/       \u001b[01;34msynthetic-data\u001b[0m/\n",
            "all_data_angio_L2_zoom_BS16.hdf5  model_BNfalse.py  \u001b[01;34msynthetic-data-modelE\u001b[0m/\n",
            "best_images.zip                   model.py\n",
            "Combined_Network_V7.h5            \u001b[01;34m__pycache__\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uenzJ7K7NTPO",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d90ff5-3acb-4b23-a64a-470766f16671"
      },
      "source": [
        "#@title Python Imports\n",
        "\n",
        "import os\n",
        "from io import BytesIO\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.filters import unsharp_mask\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from model import preprocess_input\n",
        "from PIL import Image\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELYaVN5CUNy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b78428-858b-4460-bb66-677120699c43"
      },
      "source": [
        "#@title create Deeplab model and load weights\n",
        "\n",
        "#create model instance\n",
        "\n",
        "def create_model():\n",
        "  from model_BNfalse import Deeplabv3\n",
        "  from tensorflow.keras.layers import Input, Conv2D, Dense, Activation, BatchNormalization\n",
        "  from tensorflow.keras.models import Sequential, Model\n",
        "  inputs = Input(shape=(512, 512, 1))\n",
        "\n",
        "  activation_func = None\n",
        "  X1 = Conv2D(1, (5,5), strides=(1, 1), padding='same', dilation_rate=(1, 1), activation=activation_func, \n",
        "              use_bias=False, data_format=\"channels_last\")(inputs)\n",
        "  X2 = Conv2D(1, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), activation=activation_func, \n",
        "              use_bias=False, data_format=\"channels_last\")(X1)\n",
        "  X3 = Conv2D(16, (5,5), strides=(1, 1), padding='same', dilation_rate=(1, 1), activation=activation_func, \n",
        "              use_bias=False, data_format=\"channels_last\")(X2)\n",
        "  X4 = Conv2D(16, (5,5), strides=(1, 1), padding='same', dilation_rate=(1, 1), activation=activation_func, \n",
        "              use_bias=False, data_format=\"channels_last\")(X3)\n",
        "  X5 = Conv2D(16, (5,5), strides=(1, 1), padding='same', dilation_rate=(1, 1), activation=activation_func, \n",
        "              use_bias=False, data_format=\"channels_last\")(X4)\n",
        "  X6 = Conv2D(1, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), activation='tanh', \n",
        "              use_bias=False, data_format=\"channels_last\")(X5)\n",
        "  X7 = tf.keras.layers.concatenate([X6, X6, X6], axis=3)  \n",
        "\n",
        "  unsharp_mask_model = Model(inputs=inputs, outputs=X7)\n",
        "  deeplab_model = Deeplabv3(weights=None,backbone='xception',input_shape=(512,512,3), classes=2)\n",
        "\n",
        "  combined_inputs = Input(shape=(512, 512, 1))\n",
        "  unsharp_mask_img = unsharp_mask_model(combined_inputs)\n",
        "  deeplab_img = deeplab_model(unsharp_mask_img)\n",
        "  model = Model(combined_inputs,deeplab_img)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "#model.load_weights('Combined_Network_V7.h5')\n",
        "model.load_weights(\"all_data_angio_L2_zoom_BS16.hdf5\")\n",
        "print('model loaded successfully!')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model loaded successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Chsl4uUWVG"
      },
      "source": [
        "# **Run on sample images**\n",
        "Upload any sample image file and copy the image filename to open it in the next code block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYaIIfDJkAD8"
      },
      "source": [
        "#@title upload sample image zip folder\n",
        "!unzip -uq best_images.zip -d ./\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkEX12-hBlmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc2789e-04b6-4204-ca3f-59c531d86071"
      },
      "source": [
        "#@title Create data pipeline\n",
        "def label_preprocess(image):\n",
        "  x = image==1\n",
        "  x = x.astype('float32')\n",
        "  return x\n",
        "\n",
        "data_gen_args = dict(preprocessing_function = preprocess_input);\n",
        "label_gen_args = dict(preprocessing_function = label_preprocess);\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**label_gen_args)\n",
        "\n",
        "seed = 0\n",
        "\n",
        "batchsize = 1;\n",
        "\n",
        "image_generator = image_datagen.flow_from_directory(\n",
        "    './synthetic-data-modelE/',\n",
        "    target_size=(512,512),\n",
        "    color_mode='grayscale',\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    batch_size=batchsize,\n",
        "    seed=seed)\n",
        "\n",
        "# mask_generator = mask_datagen.flow_from_directory(\n",
        "#     './5goodimages/label',\n",
        "#     target_size=(512,512),\n",
        "#     color_mode='grayscale',\n",
        "#     class_mode=None,\n",
        "#     shuffle=False,\n",
        "#     batch_size=batchsize,\n",
        "#     seed=seed)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 21 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BrjAswzUbvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82626463-d34f-4d62-9691-4e56020861bb"
      },
      "source": [
        "#@title Generate segmentations of sample images\n",
        "\n",
        "inference = model.predict(image_generator, batch_size=None, verbose=1, steps=21, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 52s 2s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVQPfftbIxML"
      },
      "source": [
        "image_generator.reset()\n",
        "#mask_generator.reset()\n",
        "\n",
        "for i in range(21):\n",
        "  img = image_generator.next()\n",
        "  filename = image_generator.filenames[i][:-4]\n",
        "  #label = mask_generator.next()\n",
        "\n",
        "  #plt.figure(); plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
        "  #plt.figure(); plt.imshow(np.squeeze(label), cmap=\"gray\")\n",
        "  full_sample = tf.nn.softmax(inference[i,:,:,:])\n",
        "\n",
        "  pred = tf.argmax(full_sample, axis=-1)\n",
        "  pred = pred.numpy() > 0\n",
        "  # plt.figure()\n",
        "  plt.imsave(\"./synthetic-data-modelE/{}_prediction.png\".format(filename),pred, cmap=\"gray\")"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}